tvb-robot
==========

***Cognitive robotics with the virtual brain platform***


TVB wasn't designed to model cognitive processes or neural computations per se, and certainly not to control robots. 
Nevertheless, owing to the quality and flexibility of the platform's design, some version of each of these should be well-within its capabilities. Controlling a robot with a TVB-simulated brain is unlikely to match the impressive achievements of e.g. [nengo](http://www.nengo.ca/), but 'exploring the dynamic landscape' of possibilities could potentially yield some useful insights into plasticity, BCIs, and embodied cognition. At the very least, it should open up some new avenues at the interface of robotics, programming, and neuroscience *education*, which is a very appealing combo. And it will be fun. And it will look very cool.

*tvb-robot* projects will be faced with three main challenges:

1. How to do real-time simulation outputs, and ideally also real-time stimulus inputs and parameter adjustment
2. How best to associate model variables with e.g. motor actions, or more abstract motor programs
3. Whether and how to use supervised learning to 'teach' the bot brain interesting things


This repository is a focal-point for any and all code, ideas, and literature reviews of broad relevance to *tvb-robot* projects. You are positively encouraged to make contributions, great and small, via the traditional fork-and-pull, and/or via github's comments and wiki functionalities. 

Happy `botting!

